{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csJuTIK8f8Ac"
   },
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7n8gBfigJsK"
   },
   "source": [
    "#### **Build a relevent machine learning model for language detection using natural language processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckF7Kb6G4ASm"
   },
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n9yxrV6apdYR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQBWb1PG4Fs4"
   },
   "source": [
    "Connect with Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24716,
     "status": "ok",
     "timestamp": 1749204244515,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "45kgDpwehtBP",
    "outputId": "15b900b7-32a1-409b-c962-712bc049d092"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ympTlDe4nq5"
   },
   "source": [
    "Import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 2742,
     "status": "ok",
     "timestamp": 1749204255568,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "vOy-smUah6hh",
    "outputId": "a2ba5293-5a8c-4f56-800e-d685bcf6bb43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  pÃ¥ eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™ thanon charoen krung à¹€...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>à®µà®¿à®šà®¾à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà®¿à®©à®®à¯ à®¤à®®à®¿à®´à¯à®šà¯à®šà®™à¯à®•à®¤à¯à®¤à¯ˆ à®‡à®¨à¯à®¤à¯à®ªà¯ à®ªà®¤à¯à®¤à®¿à®°...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>hors du terrain les annÃ©es  et  sont des annÃ©e...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>à¹ƒà¸™ à¸à¸¨  à¸«à¸¥à¸±à¸à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹€à¸ªà¸”à¹‡à¸ˆà¸›à¸£à¸°à¸à¸²à¸ªà¹à¸«à¸¥à¸¡à¸¡à¸¥à¸²à¸¢à¸¹ à¸Šà¸§à¸² à¸­à¸´à¸™à¹€...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>con motivo de la celebraciÃ³n del septuagÃ©simoq...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>å¹´æœˆï¼Œç•¶æ™‚é‚„åªæœ‰æ­²çš„å¥¹åœ¨ç¾åœ‹å‡ºé“ï¼Œä»¥mai-kåç¾©æ¨å‡ºé¦–å¼µè‹±æ–‡ã€Šbaby i likeã€‹ï¼Œç”±...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>aprilie sonda spaÈ›ialÄƒ messenger a nasa È™i-a ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  language\n",
       "0      klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1      sebes joseph pereira thomas  pÃ¥ eng the jesuit...   Swedish\n",
       "2      à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™ thanon charoen krung à¹€...      Thai\n",
       "3      à®µà®¿à®šà®¾à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà®¿à®©à®®à¯ à®¤à®®à®¿à®´à¯à®šà¯à®šà®™à¯à®•à®¤à¯à®¤à¯ˆ à®‡à®¨à¯à®¤à¯à®ªà¯ à®ªà®¤à¯à®¤à®¿à®°...     Tamil\n",
       "4      de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "...                                                  ...       ...\n",
       "21995  hors du terrain les annÃ©es  et  sont des annÃ©e...    French\n",
       "21996  à¹ƒà¸™ à¸à¸¨  à¸«à¸¥à¸±à¸à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹€à¸ªà¸”à¹‡à¸ˆà¸›à¸£à¸°à¸à¸²à¸ªà¹à¸«à¸¥à¸¡à¸¡à¸¥à¸²à¸¢à¸¹ à¸Šà¸§à¸² à¸­à¸´à¸™à¹€...      Thai\n",
       "21997  con motivo de la celebraciÃ³n del septuagÃ©simoq...   Spanish\n",
       "21998  å¹´æœˆï¼Œç•¶æ™‚é‚„åªæœ‰æ­²çš„å¥¹åœ¨ç¾åœ‹å‡ºé“ï¼Œä»¥mai-kåç¾©æ¨å‡ºé¦–å¼µè‹±æ–‡ã€Šbaby i likeã€‹ï¼Œç”±...   Chinese\n",
       "21999   aprilie sonda spaÈ›ialÄƒ messenger a nasa È™i-a ...  Romanian\n",
       "\n",
       "[22000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df =pd.read_csv(\"language.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749204279545,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "hINQVOaeflQb",
    "outputId": "38b8c342-8f82-4f64-df16-6c7305ec02ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      22000 non-null  object\n",
      " 1   language  22000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1749204303490,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "zTqRQzl-jr3U",
    "outputId": "ec5e2eeb-8337-45b1-817b-b36be6b43edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        klement gottwaldi surnukeha palsameeriti ning ...\n",
       "1        sebes joseph pereira thomas  pÃ¥ eng the jesuit...\n",
       "2        à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™ thanon charoen krung à¹€...\n",
       "3        à®µà®¿à®šà®¾à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà®¿à®©à®®à¯ à®¤à®®à®¿à®´à¯à®šà¯à®šà®™à¯à®•à®¤à¯à®¤à¯ˆ à®‡à®¨à¯à®¤à¯à®ªà¯ à®ªà®¤à¯à®¤à®¿à®°...\n",
       "4        de spons behoort tot het geslacht haliclona en...\n",
       "                               ...                        \n",
       "21995    hors du terrain les annÃ©es  et  sont des annÃ©e...\n",
       "21996    à¹ƒà¸™ à¸à¸¨  à¸«à¸¥à¸±à¸à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹€à¸ªà¸”à¹‡à¸ˆà¸›à¸£à¸°à¸à¸²à¸ªà¹à¸«à¸¥à¸¡à¸¡à¸¥à¸²à¸¢à¸¹ à¸Šà¸§à¸² à¸­à¸´à¸™à¹€...\n",
       "21997    con motivo de la celebraciÃ³n del septuagÃ©simoq...\n",
       "21998    å¹´æœˆï¼Œç•¶æ™‚é‚„åªæœ‰æ­²çš„å¥¹åœ¨ç¾åœ‹å‡ºé“ï¼Œä»¥mai-kåç¾©æ¨å‡ºé¦–å¼µè‹±æ–‡ã€Šbaby i likeã€‹ï¼Œç”±...\n",
       "21999     aprilie sonda spaÈ›ialÄƒ messenger a nasa È™i-a ...\n",
       "Name: Text, Length: 22000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1749204321057,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "AzZwCNc6s52p",
    "outputId": "6476887d-83bc-4f3b-bed2-5a4a6bda2ceb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>21859</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>haec commentatio automatice praeparata res ast...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>48</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  language\n",
       "count                                               22000     22000\n",
       "unique                                              21859        22\n",
       "top     haec commentatio automatice praeparata res ast...  Estonian\n",
       "freq                                                   48      1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObAoHsOptTyx"
   },
   "source": [
    "CountVectorizer is a tool from Scikit-learn used in Natural Language Processing (NLP) to convert text data into numerical features (so that machine learning models can understand it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1749204362967,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "4nM9IXWgjy5-",
    "outputId": "ad58afcd-b259-446e-b776-f5ee8b0da5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data' 'learning' 'love' 'machine' 'science']\n",
      "[[1 0 1 0 1]\n",
      " [0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see how it works\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#Sample text data\n",
    "data = [\"love data science\",\"love machine learning\"]\n",
    "\n",
    "#Fit and transform the data\n",
    "vectorized_data = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the vocabulary(unique words)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Convert the result to an array\n",
    "print(vectorized_data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1749204537145,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "owuT8sQos_6O",
    "outputId": "7ce4b246-57fd-4543-b7a9-b9ef34ce3fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking is their any null value or not\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1749204538147,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "Zi2ZzH6WtaxX",
    "outputId": "c5bcae48-0a3e-4234-9a58-4323bb0a16fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the language counts with value counts\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHlNIg7mu1Tt"
   },
   "source": [
    " assigning text column in X and language column in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1749204967379,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "WQZMgXDkt5hE",
    "outputId": "15564db7-61dc-4e7b-9244-1d092d67573e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha mausoleumist Ã¤ra ja kremeeriti zlÃ­ni linn kandis aastatel â€“ nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel â€“ nime gotvald'\n",
      " 'sebes joseph pereira thomas  pÃ¥ eng the jesuits and the sino-russian treaty of nerchinsk  the diary of thomas pereira bibliotheca instituti historici s i --   rome libris '\n",
      " 'à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™ thanon charoen krung à¹€à¸£à¸´à¹ˆà¸¡à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸–à¸™à¸™à¸ªà¸™à¸²à¸¡à¹„à¸Šà¸¢à¸–à¸¶à¸‡à¹à¸¡à¹ˆà¸™à¹‰à¸³à¹€à¸ˆà¹‰à¸²à¸à¸£à¸°à¸¢à¸²à¸—à¸µà¹ˆà¸–à¸™à¸™à¸•à¸ à¸à¸£à¸¸à¸‡à¹€à¸—à¸à¸¡à¸«à¸²à¸™à¸„à¸£ à¹€à¸›à¹‡à¸™à¸–à¸™à¸™à¸£à¸¸à¹ˆà¸™à¹à¸£à¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹€à¸—à¸„à¸™à¸´à¸„à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹à¸šà¸šà¸•à¸°à¸§à¸±à¸™à¸•à¸ à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸œà¹ˆà¸²à¸™à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¹€à¸‚à¸•à¸à¸£à¸°à¸™à¸„à¸£ à¹€à¸‚à¸•à¸›à¹‰à¸­à¸¡à¸›à¸£à¸²à¸šà¸¨à¸±à¸•à¸£à¸¹à¸à¹ˆà¸²à¸¢ à¹€à¸‚à¸•à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¸§à¸‡à¸¨à¹Œ à¹€à¸‚à¸•à¸šà¸²à¸‡à¸£à¸±à¸ à¹€à¸‚à¸•à¸ªà¸²à¸—à¸£ à¹à¸¥à¸°à¹€à¸‚à¸•à¸šà¸²à¸‡à¸„à¸­à¹à¸«à¸¥à¸¡'\n",
      " ...\n",
      " 'con motivo de la celebraciÃ³n del septuagÃ©simoquinto Â° aniversario de la fundaciÃ³n del departamento en  guillermo ceballos espinosa presentÃ³ a la gobernaciÃ³n de caldas por encargo de su titular dilia estrada de gÃ³mez el himno que fue adoptado para solemnizar dicha efemÃ©rides y que siguieron interpretando las bandas de mÃºsica y los planteles de educaciÃ³n de esta secciÃ³n del paÃ­s en retretas y actos oficiales con gran aceptaciÃ³n[]\\u200b'\n",
      " 'å¹´æœˆï¼Œç•¶æ™‚é‚„åªæœ‰æ­²çš„å¥¹åœ¨ç¾åœ‹å‡ºé“ï¼Œä»¥mai-kåç¾©æ¨å‡ºé¦–å¼µè‹±æ–‡ã€Šbaby i likeã€‹ï¼Œç”±ç¾åœ‹çš„ç¨ç«‹å» ç‰ŒbipÂ·recordç™¼è¡Œï¼Œä»¥å¤–åœ‹è¼¸å…¥ç›¤çš„å½¢å¼åœ¨æ—¥æœ¬ç™¼å”®ï¼Œæ—‹å³è¢«æŠ¢è´­ä¸€ç©ºã€‚å…¶å¾Œæ–¼æœˆæ—¥ç™¼è¡Œä»¥å€‰æœ¨éº»è¡£åç¾©ç™¼è¡Œçš„é¦–å¼µæ—¥æ–‡å–®æ›²ã€Šlove day after tomorrowã€‹ï¼Œæ­£å¼æ–¼æ—¥æœ¬å‡ºé“ã€‚é€™å¼µå–®æ›²åˆå‹•éŠ·é‡åªå¾—ç´„è¬å¼µï¼Œå¯æ˜¯å…¶å¾Œæ¯é€±éŠ·é‡ä¸€ç›´ä¸Šå‡ï¼Œä¸¦æ–¼å¹´æœˆæ­£å¼çªç ´ç™¾è¬éŠ·é‡ï¼Œåˆè®¡ä¸‡å¼ ã€‚æˆç‚ºå¹´æœ€è€€çœ¼çš„æ–°äººæ­Œæ‰‹ã€‚'\n",
      " ' aprilie sonda spaÈ›ialÄƒ messenger a nasa È™i-a Ã®ncheiat misiunea de studiu de  ani prÄƒbuÈ™indu-se pe suprafaÈ›a planetei mercur sonda a rÄƒmas fÄƒrÄƒ combustibil fiind Ã®mpinsÄƒ de gravitaÈ›ia solarÄƒ din ce Ã®n ce mai aproape de mercur']\n",
      "language: ['Estonian' 'Swedish' 'Thai' ... 'Spanish' 'Chinese' 'Romanian']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array(df[\"Text\"])\n",
    "y = np.array(df[\"language\"])\n",
    "\n",
    "print(\"Text:\",x)\n",
    "print(\"language:\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtYHlkWbvHwG"
   },
   "source": [
    " converting text into number with count vectorizer and splitting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RLwNqM_4ueUO"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "X_train ,X_test ,y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPyDiaxevOeM"
   },
   "source": [
    " fitting the train and test data in model(MultinomailNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1749204979103,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "DR_zlOfrwiB_",
    "outputId": "4523a11c-9846-4147-e76c-2d94438601d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953168044077135"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)   # checking the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyodliZavUkH"
   },
   "source": [
    "Checking the language model is working right or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123777,
     "status": "ok",
     "timestamp": 1749205107715,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "QbPX9Gv7w1Nq",
    "outputId": "f3f66cfe-1127-4cd9-a674-239f5579ebf3"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a Text: i love you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user = input(\"Enter a Text:\")\n",
    "df = cv.transform([user]).toarray()\n",
    "output = model.predict(df)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBpmpLJHvgQb"
   },
   "source": [
    "###  Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     ------------------------------ ------- 786.4/981.5 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 1.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993251 sha256=c13abb7d4cb310fcb19d90273a1d9a8cfb3f0552037c08a32de5fdc1b6afae66\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install langdetect\n",
    "\n",
    "from langdetect import detect\n",
    "import pickle\n",
    "\n",
    "# Define a function\n",
    "def detect_language(text):\n",
    "    return detect(text)\n",
    "\n",
    "# Save the function using pickle\n",
    "with open(\"NLP_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(detect_language, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1703,
     "status": "ok",
     "timestamp": 1749207200259,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "-6rlmECSxY8f",
    "outputId": "08b3a71f-f773-4993-f792-64f217be293a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model (after fitting)\n",
    "joblib.dump(model, \"NLP_model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… app.py created successfully.\n"
     ]
    }
   ],
   "source": [
    "app_code = '''\n",
    "import streamlit as st\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "with open(\"NLP_model.pkl.pkl\", \"rb\") as f:\n",
    "    detect_language = pickle.load(f)\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(page_title=\"Language Detection App\")\n",
    "\n",
    "st.title(\"ğŸŒ Language Detection Using NLP\")\n",
    "st.write(\"Enter text below to detect the language:\")\n",
    "\n",
    "user_input = st.text_area(\"Text Input\", height=150)\n",
    "\n",
    "if st.button(\"Detect Language\"):\n",
    "    if user_input.strip() == \"\":\n",
    "        st.warning(\"Please enter some text.\")\n",
    "    else:\n",
    "        try:\n",
    "            language = detect_language(user_input)\n",
    "            st.success(f\"Detected Language Code: `{language}`\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error detecting language: {str(e)}\")\n",
    "'''\n",
    "\n",
    "with open(\"app.py\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(app_code)\n",
    "\n",
    "\n",
    "print(\"âœ… app.py created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1749207332423,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "7aT7EcOEjjE5",
    "outputId": "ef4c19e2-5091-49e8-9946-66e734d6b369"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download(\"NLP_model.pkl\")\n",
    "# files.download(\"vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1749208697741,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "LkPjr0F2jvAE",
    "outputId": "7b59141c-a9f7-4a88-89d8-8bef375e92ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\CDS\\Practice\\Untitled Folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8243,
     "status": "ok",
     "timestamp": 1749209152880,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "zc0aYKhu59Bf",
    "outputId": "4e0a1259-4efe-4fa8-9734-169020a34d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# !pip install streamlit pyngrok --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 501556,
     "status": "ok",
     "timestamp": 1749209687379,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "_-S6drfx_Vvj",
    "outputId": "3be67942-57e3-4540-abc7-f8fba524e9dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-dce593d6-de7b-4786-b5ce-b884ddde056f\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-dce593d6-de7b-4786-b5ce-b884ddde056f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving NLP_model.pkl to NLP_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 8764,
     "status": "ok",
     "timestamp": 1749209726060,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "0vf16M-U_fza",
    "outputId": "f1538a4d-2fbc-447c-820d-50bc6b41122e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a2936d2b-ee9d-44a7-a738-9e02c3a651bf\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a2936d2b-ee9d-44a7-a738-9e02c3a651bf\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vectorizer.pkl to vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1749210437156,
     "user": {
      "displayName": "Tanishq Sahu",
      "userId": "18285156580621575003"
     },
     "user_tz": -330
    },
    "id": "IQfvyNLRBhjb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGg9wFkTCBAz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaHcSub8eAfjH2ExQhIQF5",
   "provenance": [
    {
     "file_id": "1DoDBM97-Sf_dT5e_yAXzHWaiRXXFiE5A",
     "timestamp": 1749134034814
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
